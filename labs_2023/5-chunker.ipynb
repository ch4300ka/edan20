{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x227614752b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = {}\n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    if target_word not in embeddings:\n",
    "        return []\n",
    "    \n",
    "    def normalize(word):\n",
    "        vector = embeddings[word]\n",
    "        return vector / norm(vector)\n",
    "\n",
    "    def cosine_similarity(A, B, V):\n",
    "        if (A, B) not in cosine_similarities:\n",
    "            cosine_similarities[(A, B)] = cosine_similarities[(B, A)] = np.dot(V, normalize(B))\n",
    "\n",
    "        return cosine_similarities[(A, B)]\n",
    "    \n",
    "    V = normalize(target_word)\n",
    "\n",
    "    return [word for (word, _) in sorted([(word, cosine_similarity(target_word, word, V)) for word in embeddings.keys()], key=lambda x: x[1], reverse=True)[:count]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for sentence in corpus_dict:\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "\n",
    "        for dictionary in sentence:\n",
    "            l1.append(dictionary[key_x] if not tolower else dictionary[key_x].lower())\n",
    "            l2.append(dictionary[key_y])\n",
    "\n",
    "        X.append(l1)\n",
    "        Y.append(l2)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words  = set()\n",
    "chunks = set()\n",
    "\n",
    "for sentence in train_dict:\n",
    "    for dictionary in sentence:\n",
    "        words.add(dictionary[\"form\"].lower())\n",
    "        chunks.add(dictionary[\"chunk\"])\n",
    "\n",
    "words  = sorted(words)\n",
    "chunks = sorted(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(set(embedded_words + words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = {}\n",
    "word2idx = {}\n",
    "\n",
    "for (idx, word) in (enumerate(vocabulary_words, 2)):\n",
    "    idx2word[idx] = word\n",
    "    word2idx[word] = idx\n",
    "\n",
    "idx2chunk = {}\n",
    "chunk2idx = {}\n",
    "\n",
    "for (idx, chunk) in (enumerate(chunks, 1)):\n",
    "    idx2chunk[idx] = chunk\n",
    "    chunk2idx[chunk] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict.keys():\n",
    "        embedding_matrix[word2idx[word]] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = [[word2idx[word] for word in sentence] for sentence in X_train_symbs]\n",
    "Y_train_idx = [[chunk2idx[chunk] for chunk in sentence] for sentence in Y_train_symbs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True, padding_value=0)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False, use_rnn=False):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstmUnits = lstm_units\n",
    "        self.embeddings = nn.Embedding.from_pretrained(torch.from_numpy(embedding_matrix).float(), padding_idx=0)\n",
    "        if use_rnn:\n",
    "            self.rnn = nn.RNN(embedding_dim, lstm_units, batch_first=True, bidirectional=bidi_lstm)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=bidi_lstm)\n",
    "        self.fc = nn.Linear(lstm_units*2, nbr_classes)\n",
    "        self.use_rnn=use_rnn\n",
    "\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeddings = self.embeddings(sentence)\n",
    "        if self.use_rnn:\n",
    "            rnn, _ = self.rnn(embeddings)\n",
    "            logits = self.fc(rnn)\n",
    "        else:\n",
    "            lstm, _ = self.lstm(embeddings)\n",
    "            logits = self.fc(lstm)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True, use_rnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (rnn): RNN(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:07<00:00, 37.22it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 35.49it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 38.19it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 37.38it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 37.23it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 38.18it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 36.19it/s]\n",
      "100%|██████████| 280/280 [00:08<00:00, 33.15it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 38.43it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 38.53it/s]\n",
      "100%|██████████| 280/280 [00:07<00:00, 39.74it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 40.13it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 40.74it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 40.29it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 42.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc  = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [word2idx.get(word, 1) for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_chunk_predictions = model1(torch.LongTensor(sentence_word_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.0385e-12, 5.8846e-06, 4.4939e-04, 2.6977e-10, 3.4601e-07, 1.0195e-08,\n",
       "        9.9914e-01, 8.7400e-05, 1.4307e-09, 3.0399e-10, 5.1615e-11, 1.3901e-06,\n",
       "        8.4856e-08, 3.2084e-08, 3.9447e-12, 1.2115e-09, 8.9470e-05, 3.6472e-10,\n",
       "        6.2637e-08, 2.0292e-11, 3.5433e-10, 8.1204e-08, 2.2472e-04],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11,  6, 22])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: B-NP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = [[word2idx.get(word, 1) for word in sentence] for sentence in X_test_symbs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(torch.LongTensor(X_test_padded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[ -8.9739,   3.5286,   0.4938,  ...,  -3.4108,  -2.7427,   5.8091],\n",
      "        [-11.6248,   1.1483,   4.7653,  ...,  -7.8786,   7.2832,   7.8689],\n",
      "        [ -9.6106,   3.0955,   5.2956,  ...,  -5.4326,  -2.5699,   6.9056],\n",
      "        ...,\n",
      "        [ 14.5644,  -8.8822,  -6.1938,  ..., -12.2756,  -4.3926,  -1.1491],\n",
      "        [ 16.1055, -11.7460,  -7.9775,  ..., -10.8415,  -7.2326,  -0.1094],\n",
      "        [ 24.5606, -16.7188, -12.9600,  ...,  -9.4530, -13.3182,  -6.0708]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-PP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8556599110232328"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
